---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: spark-operator
  namespace: kubeflow
spec:
  interval: 24h
  url: https://kubeflow.github.io/spark-operator
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: spark-operator
  namespace: kubeflow
spec:
  interval: 5m
  chart:
    spec:
      chart: spark-operator
      version: "2.1.0"
      sourceRef:
        kind: HelmRepository
        name: spark-operator
        namespace: kubeflow
      interval: 24h
  values:
    serviceAccount:
      # -- Specifies whether to create a service account for the controller.
      create: false
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: spark-operator-spark
  namespace: kubeflow
---
# Grant all permissions over services, pods, persistentvolumeclaims, and configmaps in the namespace (kubeflow)
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: spark-operator-role
  namespace: kubeflow
rules:
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["*"]  # All permissions: create, delete, get, list, watch, update, patch
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["*"]  # All permissions
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["*"]  # All permissions
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["*"]  # All permissions
---
# Bind the above Role to the spark-operator ServiceAccount
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: spark-operator-rolebinding
  namespace: kubeflow
subjects:
  - kind: ServiceAccount
    name: spark-operator-spark
    namespace: kubeflow
roleRef:
  kind: Role
  name: spark-operator-role
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-pi
  namespace: kubeflow
spec:
  type: Scala
  mode: cluster
  image: "gcr.io/spark-operator/spark:v3.1.1"
  imagePullPolicy: Always
  mainClass: org.apache.spark.examples.SparkPi
  mainApplicationFile: "local:///opt/spark/examples/jars/spark-examples_2.12-3.1.1.jar"
  sparkVersion: "3.1.1"
  restartPolicy:
    type: Never
  volumes:
    - name: "test-volume"
      hostPath:
        path: "/tmp"
        type: Directory
  driver:
    cores: 1
    coreLimit: "1200m"
    memory: "512m"
    labels:
      version: 3.1.1
    # Ensure the service account matches what is set up by the spark-operator HelmRelease
    serviceAccount: spark-operator-spark
    volumeMounts:
      - name: "test-volume"
        mountPath: "/tmp"
  executor:
    cores: 1
    instances: 1
    memory: "512m"
    labels:
      version: 3.1.1
    volumeMounts:
      - name: "test-volume"
        mountPath: "/tmp"
