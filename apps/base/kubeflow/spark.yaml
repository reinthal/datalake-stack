---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: spark-operator
  namespace: kubeflow
spec:
  interval: 24h
  url: https://kubeflow.github.io/spark-operator
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: spark-operator
  namespace: kubeflow
spec:
  interval: 5m
  chart:
    spec:
      chart: spark-operator
      version: "2.1.0"
      sourceRef:
        kind: HelmRepository
        name: spark-operator
        namespace: kubeflow
      interval: 24h
  values:
    serviceAccount:
      # -- Specifies whether to create a service account for the controller.
      create: false
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: spark-operator-spark
  namespace: kubeflow
---
# Grant all permissions over services, pods, persistentvolumeclaims, and configmaps in the namespace (kubeflow)
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: spark-operator-role
  namespace: kubeflow
rules:
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["*"]  # All permissions: create, delete, get, list, watch, update, patch
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["*"]  # All permissions
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["*"]  # All permissions
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["*"]  # All permissions
---
# Bind the above Role to the spark-operator ServiceAccount
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: spark-operator-rolebinding
  namespace: kubeflow
subjects:
  - kind: ServiceAccount
    name: spark-operator-spark
    namespace: kubeflow
roleRef:
  kind: Role
  name: spark-operator-role
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: spark-pi-dynamic-allocation
  namespace: default
spec:
  type: Scala
  mode: cluster
  image: spark:3.5.2
  imagePullPolicy: IfNotPresent
  mainClass: org.apache.spark.examples.SparkPi
  mainApplicationFile: local:///opt/spark/examples/jars/spark-examples_2.12-3.5.2.jar
  sparkVersion: 3.5.2
  arguments:
  - "50000"
  driver:
    labels:
      version: 3.5.2
    cores: 1
    coreLimit: 1200m
    memory: 512m
    serviceAccount: spark-operator-spark
  executor:
    labels:
      version: 3.5.2
    instances: 1
    cores: 1
    coreLimit: 1200m
    memory: 512m
  dynamicAllocation:
    enabled: true
    initialExecutors: 2
    maxExecutors: 5
    minExecutors: 1
